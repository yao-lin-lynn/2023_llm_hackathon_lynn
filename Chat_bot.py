import os
import openai
import streamlit as st
from streamlit_chat import message
from llama_index import VectorStoreIndex, SimpleDirectoryReader


openai_api_key = os.getenv("OPENAI_API_KEY")
documents = SimpleDirectoryReader(input_dir="./data").load_data()
index = VectorStoreIndex.from_documents(documents)

st.title("ğŸ’¬ ã«ã‚ƒã‚“ã½ã‚“ã‚Šã‚“GPT")
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": "ãƒ˜ã‚¤ï¼ã“ã‚“ã«ã¡ã¯ã€åƒ•ã¯SmartHRã§åƒã„ã¦ã„ã‚‹äººã«è©³ã—ã„ã®ã§ã€ç›¸è«‡ã—ãŸã„äººã«ã¤ã„ã¦ãªã‚“ã§ã‚‚èã„ã¦ã­ï¼"}]

with st.form("chat_input", clear_on_submit=True):
    a, b = st.columns([4, 1])
    user_input = a.text_input(
        label="Your message:",
        placeholder="èããŸã„ã“ã¨ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„",
        label_visibility="collapsed",
    )
    b.form_submit_button("é€ä¿¡", use_container_width=True)

for msg in st.session_state.messages:
    message(msg["content"], is_user=msg["role"] == "user")
    
if user_input and openai_api_key:
    openai.api_key = openai_api_key
    st.session_state.messages.append({"role": "user", "content": user_input})
    message(user_input, is_user=True)
    query_engine = index.as_query_engine(similarity_top_k=3,
    vector_store_query_mode="default")
    print(st.session_state.messages)
    response = query_engine.query(user_input)
    # response = openai.ChatCompletion.create(model="gpt-3.5-turbo", messages=st.session_state.messages)
    # msg = response.choices[0].message
    # st.session_state.messages.append(msg)
    st.session_state.messages.append({"role": "assistant", "content": response.response})
    message(response.response)
